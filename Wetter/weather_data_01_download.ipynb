{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from urllib import request\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1># 01 - Wetterdaten: Herunterladen der Dateien der für die definierten Station-IDs </h1>\n",
    "<hr>\n",
    "<p><b>Hinweis:</b> Dateifpade sind absolut angegeben und müssen entsprechend der eigenen Verzeichnisstruktur angepasst werden!</p>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wetterstation-IDs der jeweiligen Städte (manuell ermittelt)\n",
    "# https://www.ncei.noaa.gov/maps/hourly/\n",
    "\n",
    "\n",
    "stations_id_berlin = [\n",
    " '10382099999'\n",
    ",'10385099999'    \n",
    "]\n",
    "\n",
    "stations_id_tokyo = [\n",
    " \"47671099999\"\n",
    ",\"47662099999\"\n",
    ",\"47687099999\"\n",
    "]\n",
    "\n",
    "stations_id_london = [\n",
    " \"03768399999\"\n",
    "]\n",
    "\n",
    "stations_id_newyork = [\n",
    " \"72505394728\"\n",
    ",\"72502014734\"\n",
    "]\n",
    "\n",
    "stations_id_chicago = [\n",
    "\"72534014819\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zum Herunterladen der einzelnen Dateien: Pro Jahr und Station-ID\n",
    "def download_file(src, tgt, year, station_ids):\n",
    "    # Quellpfad mit \"Jahr\"\n",
    "    year_url = src + str(year) + '/'\n",
    "    # Über die Stationen iterieren und Daten herunterladen\n",
    "    for id in station_ids:\n",
    "        full_url = year_url + id + '.csv' # Quell-Url\n",
    "        full_local_file = tgt + id + '_' + str(year) + '.csv' # Ziel-Url\n",
    "        try:\n",
    "            request.urlretrieve(full_url, full_local_file) # Datei herunterladen            \n",
    "        except request.HTTPError:\n",
    "            # Falls Datei nicht vorhanden, dann überspringen\n",
    "            print('Nicht gefunden: ' + full_url)\n",
    "        time.sleep(5) # Times sleep, um häufige Anfragen an den Server zu reduzieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jahre, Quell- und Ziel-URL definieren\n",
    "years = range(2007,2020)\n",
    "main_url = 'https://www.ncei.noaa.gov/data/global-hourly/access/'\n",
    "download_path = '/home/paul/python_projects/masterthesis/data/wetter/downloaded/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten herunterladen: Berlin\n",
    "for year in years:\n",
    "    download_file(main_url, download_path, year, stations_id_berlin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten herunterladen: Tokyo\n",
    "for year in years:\n",
    "    download_file(main_url, download_path, year, stations_id_tokyo) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten herunterladen: London\n",
    "for year in years:\n",
    "    download_file(main_url, download_path, year, stations_id_london) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten herunterladen: NewYork\n",
    "for year in years:\n",
    "    download_file(main_url, download_path, year, stations_id_newyork) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten herunterladen: Chicago\n",
    "for year in years:\n",
    "    download_file(main_url, download_path, year, stations_id_chicago) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['47671099999_2012.csv', '10382099999_2011.csv', '72502014734_2010.csv', '47671099999_2009.csv', '47687099999_2013.csv', '10385099999_2014.csv', 'README.txt', '47662099999_2011.csv', '10385099999_2017.csv', '47687099999_2008.csv', '72502014734_2015.csv', '03768399999_2010.csv', '03768399999_2008.csv', '47687099999_2007.csv', '47687099999_2012.csv', '72534014819_2008.csv', '47671099999_2008.csv', '03768399999_2014.csv', '10385099999_2007.csv', '10382099999_2015.csv', '03768399999_2012.csv', '72534014819_2007.csv', '72505394728_2015.csv', '47662099999_2017.csv', '72502014734_2012.csv', '72534014819_2011.csv', '47662099999_2010.csv', '03768399999_2018.csv', '47687099999_2018.csv', '47687099999_2019.csv', '10385099999_2010.csv', '72534014819_2013.csv', '47687099999_2017.csv', '03768399999_2016.csv', '10385099999_2016.csv', '72534014819_2010.csv', '10382099999_2012.csv', '72505394728_2016.csv', '10382099999_2013.csv', '47662099999_2015.csv', '10385099999_2018.csv', '72534014819_2016.csv', '10382099999_2019.csv', '03768399999_2009.csv', '47687099999_2015.csv', '47687099999_2014.csv', '72534014819_2015.csv', '47671099999_2014.csv', '10382099999_2014.csv', '72502014734_2017.csv', '72502014734_2016.csv', '47671099999_2019.csv', '47687099999_2011.csv', '03768399999_2019.csv', '47671099999_2018.csv', '47662099999_2008.csv', '47687099999_2009.csv', '10385099999_2009.csv', '47671099999_2007.csv', '72505394728_2013.csv', '72505394728_2019.csv', '47671099999_2010.csv', '72505394728_2009.csv', '72505394728_2018.csv', '72505394728_2010.csv', '10385099999_2008.csv', '47671099999_2015.csv', '72502014734_2011.csv', '10385099999_2015.csv', '72505394728_2017.csv', '03768399999_2007.csv', '72505394728_2012.csv', '47671099999_2013.csv', '47671099999_2017.csv', '10382099999_2018.csv', '72534014819_2017.csv', '47671099999_2016.csv', '10385099999_2012.csv', '10382099999_2007.csv', '47671099999_2011.csv', '47662099999_2019.csv', '72534014819_2019.csv', '47662099999_2018.csv', '72505394728_2008.csv', '72505394728_2014.csv', '72502014734_2018.csv', '10382099999_2009.csv', '10382099999_2017.csv', '10385099999_2019.csv', '10382099999_2010.csv', '72502014734_2007.csv', '10382099999_2008.csv', '03768399999_2015.csv', '47687099999_2016.csv', '10385099999_2013.csv', '47662099999_2013.csv', '03768399999_2011.csv', '72534014819_2009.csv', '72534014819_2012.csv', '72534014819_2014.csv', '72502014734_2013.csv', '72502014734_2014.csv', '72502014734_2008.csv', '10385099999_2011.csv', '47662099999_2016.csv', '47662099999_2012.csv', '72502014734_2009.csv', '72534014819_2018.csv', '03768399999_2017.csv', '47662099999_2009.csv', '03768399999_2013.csv', '47687099999_2010.csv', '72505394728_2011.csv', '72502014734_2019.csv', '47662099999_2007.csv', '10382099999_2016.csv', '72505394728_2007.csv', '47662099999_2014.csv']\n",
      "1552015\n"
     ]
    }
   ],
   "source": [
    "# Anzahl der Datensätze ermitteltn\n",
    "dir_list = os.listdir(download_path)\n",
    "print(dir_list)\n",
    "total_lines = 0\n",
    "total_lines_over_all = 0\n",
    "for file in dir_list:\n",
    "    with open(download_path + file) as myfile:\n",
    "        total_lines = sum(1 for line in myfile)\n",
    "    total_lines_over_all = total_lines_over_all + total_lines\n",
    "\n",
    "print(total_lines_over_all) # Inklusive Header-Zeile"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a170f962d07ed8515a1e0cfe90051c8c49c07a10f515ca6de22ae850428164e9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
