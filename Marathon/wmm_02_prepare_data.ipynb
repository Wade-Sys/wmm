{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "from dateutil.parser import parse\n",
    "import time\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1># 03 - Ergebnisdaten: Finale Aufbereitung der harmonisierten Daten:</h1>\n",
    "<p><b>Hinweis:</b> Dateifpade sind absolut angegeben und müssen entsprechend der eigenen Verzeichnisstruktur angepasst werden! </p>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pfad zu den harmonisierten Daten\n",
    "data_path = '/home/paul/python_projects/masterthesis/data/wmm_data/'\n",
    "\n",
    "file_name_harm = 'daten_wmm_all_harm.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten einlesen\n",
    "df_data_csv = pd.DataFrame(pd.read_csv(data_path + file_name_harm,\n",
    "    header=0, sep=';', encoding='utf-8',\n",
    "    usecols=[\n",
    "        'Jahr', 'Ort','Geschlecht', 'Vorname', 'Nachname','Platz','Datum','Startzeit'\n",
    "        ,'T_KM_FN', 'T_KM_5', 'T_KM_10', 'T_KM_15', 'T_KM_20', 'T_KM_HM', 'T_KM_25', 'T_KM_30', 'T_KM_35', 'T_KM_40'\n",
    "    ],    \n",
    "    dtype={\n",
    "        'Jahr':str, 'Ort':str,'Geschlecht':str, 'Vorname':str, 'Nachname':str,'Platz':int,'Datum': str, 'Startzeit':str\n",
    "        ,'T_KM_FN':str, 'T_KM_5':str, 'T_KM_10':str, 'T_KM_15':str, 'T_KM_20':str, 'T_KM_HM':str, 'T_KM_25':str, 'T_KM_30':str, 'T_KM_35':str, 'T_KM_40':str\n",
    "        },\n",
    "    low_memory=False\n",
    "))\n",
    "\n",
    "df_data_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe kopieren\n",
    "df_data = df_data_csv.copy()\n",
    "\n",
    "# EM -Dash überall entfernen\n",
    "df_data.replace('–',np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datum setzen und konvertieren\n",
    "\n",
    "\n",
    "# Datum: Berlin\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2019') & (df_data['Ort'] == 'Berlin'),'2019-09-29',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2018') & (df_data['Ort'] == 'Berlin'),'2018-09-16',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2017') & (df_data['Ort'] == 'Berlin'),'2017-09-24',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2016') & (df_data['Ort'] == 'Berlin'),'2016-09-25',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2015') & (df_data['Ort'] == 'Berlin'),'2015-09-27',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2014') & (df_data['Ort'] == 'Berlin'),'2014-09-28',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2013') & (df_data['Ort'] == 'Berlin'),'2013-09-29',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2012') & (df_data['Ort'] == 'Berlin'),'2012-09-30',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2011') & (df_data['Ort'] == 'Berlin'),'2011-09-25',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2010') & (df_data['Ort'] == 'Berlin'),'2010-09-26',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2009') & (df_data['Ort'] == 'Berlin'),'2009-09-20',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2008') & (df_data['Ort'] == 'Berlin'),'2008-09-28',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2007') & (df_data['Ort'] == 'Berlin'),'2007-09-30',inplace=True)\n",
    "\n",
    "# Datum: Chicago\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2019') & (df_data['Ort'] == 'Chicago'),'2019-10-13',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2018') & (df_data['Ort'] == 'Chicago'),'2018-10-07',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2017') & (df_data['Ort'] == 'Chicago'),'2017-10-08',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2016') & (df_data['Ort'] == 'Chicago'),'2016-10-09',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2015') & (df_data['Ort'] == 'Chicago'),'2015-10-11',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2014') & (df_data['Ort'] == 'Chicago'),'2014-10-12',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2013') & (df_data['Ort'] == 'Chicago'),'2013-10-13',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2012') & (df_data['Ort'] == 'Chicago'),'2012-10-07',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2011') & (df_data['Ort'] == 'Chicago'),'2011-10-09',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2010') & (df_data['Ort'] == 'Chicago'),'2010-10-10',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2009') & (df_data['Ort'] == 'Chicago'),'2009-10-11',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2008') & (df_data['Ort'] == 'Chicago'),'2008-10-12',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2007') & (df_data['Ort'] == 'Chicago'),'2007-10-07',inplace=True)\n",
    "\n",
    "# Datum: London\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2019') & (df_data['Ort'] == 'London'),'2019-04-28',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2018') & (df_data['Ort'] == 'London'),'2018-04-22',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2017') & (df_data['Ort'] == 'London'),'2017-04-23',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2016') & (df_data['Ort'] == 'London'),'2016-04-24',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2015') & (df_data['Ort'] == 'London'),'2015-04-26',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2014') & (df_data['Ort'] == 'London'),'2014-04-13',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2013') & (df_data['Ort'] == 'London'),'2013-04-21',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2012') & (df_data['Ort'] == 'London'),'2012-04-22',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2011') & (df_data['Ort'] == 'London'),'2011-04-17',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2010') & (df_data['Ort'] == 'London'),'2010-04-25',inplace=True)\n",
    "\n",
    "# Datum: NewYork -> 2012 Auf Grund eines Unwetters fand kein Marathon statt\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2019') & (df_data['Ort'] == 'NewYork'),'2019-11-03..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2018') & (df_data['Ort'] == 'NewYork'),'2018-11-04..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2017') & (df_data['Ort'] == 'NewYork'),'2017-11-05..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2016') & (df_data['Ort'] == 'NewYork'),'2016-11-06..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2015') & (df_data['Ort'] == 'NewYork'),'2015-11-01..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2014') & (df_data['Ort'] == 'NewYork'),'2014-11-02..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2013') & (df_data['Ort'] == 'NewYork'),'2013-11-03..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2011') & (df_data['Ort'] == 'NewYork'),'2011-11-06..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2010') & (df_data['Ort'] == 'NewYork'),'2010-11-07..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2009') & (df_data['Ort'] == 'NewYork'),'2009-11-01..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2008') & (df_data['Ort'] == 'NewYork'),'2008-11-02..',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2007') & (df_data['Ort'] == 'NewYork'),'2007-11-04..',inplace=True)\n",
    "\n",
    "# Datum: Tokyo\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2019') & (df_data['Ort'] == 'Tokyo'),'2019-03-03',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2018') & (df_data['Ort'] == 'Tokyo'),'2018-02-25',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2017') & (df_data['Ort'] == 'Tokyo'),'2017-02-26',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2016') & (df_data['Ort'] == 'Tokyo'),'2016-02-28',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2015') & (df_data['Ort'] == 'Tokyo'),'2015-02-22',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2014') & (df_data['Ort'] == 'Tokyo'),'2014-02-23',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2013') & (df_data['Ort'] == 'Tokyo'),'2013-02-24',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2012') & (df_data['Ort'] == 'Tokyo'),'2012-02-26',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2011') & (df_data['Ort'] == 'Tokyo'),'2011-02-27',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2010') & (df_data['Ort'] == 'Tokyo'),'2010-02-28',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2009') & (df_data['Ort'] == 'Tokyo'),'2009-03-22',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2008') & (df_data['Ort'] == 'Tokyo'),'2008-02-17',inplace=True)\n",
    "df_data['Datum'].mask((df_data['Jahr'] == '2007') & (df_data['Ort'] == 'Tokyo'),'2007-02-18',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data['Datum']= df_data['Datum'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data[(df_data['Ort'] == 'Tokyo') & (df_data['Jahr'] == '2018')]\n",
    "df_data_2 = df_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Startzeit konvertieren\n",
    "df_data_2.groupby(['Startzeit','Ort'],dropna=False, as_index=False)[['Jahr']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konvertierung der NewYork Uhrzeiten\n",
    "df_data_2['Startzeit'].mask((df_data_2['Startzeit'] == '12:00PM') & (df_data_2['Ort'] == 'NewYork'),'12:00:00',inplace=True) # 12:00PM\n",
    "df_data_2['Startzeit'].mask((df_data_2['Startzeit'] == '8:30AM') & (df_data_2['Ort'] == 'NewYork'),'08:30:00',inplace=True) # 08:30AM\n",
    "df_data_2['Startzeit'].mask((df_data_2['Startzeit'] == '9:00AM') & (df_data_2['Ort'] == 'NewYork'),'09:00:00',inplace=True) # 09:00AM\n",
    "\n",
    "df_data_2.groupby(['Startzeit','Ort'],dropna=False, as_index=False)[['Jahr']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sekunden in der Startzeit auf 00 setzen\n",
    "for index, row in df_data_2.iterrows():    \n",
    "    start_zeit = row['Startzeit']\n",
    "    if not pd.isnull(start_zeit) and len(start_zeit) > 1:\n",
    "        #print(start_zeit[0:-2] + '00')\n",
    "        df_data_2.loc[index,['Startzeit']] = (start_zeit[0:-2] + '00')\n",
    "\n",
    "df_data_2.groupby(['Startzeit','Ort'],dropna=False, as_index=False)[['Jahr']].count()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Setzen der fehlenden Uhrzeit</h3>\n",
    "<p><b>Es wird angenommen, dass die jeweiligen Marathonläufe zu denselben Uhrzeiten beginnen. Daher werden die fehlenden Startzeiten aus den verfügbaren Zeiten der letzten oder aktuellen Läufe abgeleitet.</b></p>\n",
    "<lu>\n",
    "<li><b>Berlin: </b>09:15:00 (Startzeit 2021)</li>\n",
    "<li><b>Tokyo: </b>09:10:00 (Startzeit der letzten Jahre)</li>\n",
    "<li><b>Chicago: </b>07:30:00 (Startzeit der letzten Jahre)</li>\n",
    "</lu>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Zeiten setzen\n",
    "\n",
    "df_data_2['Startzeit'].mask((df_data_2['Ort'] == 'Berlin'),'09:15:00',inplace=True) # Berlin -> 09:15:00\n",
    "df_data_2['Startzeit'].mask((df_data_2['Ort'] == 'Tokyo'),'09:10:00',inplace=True) # Tokyo -> 09:10:00\n",
    "df_data_2['Startzeit'].mask((df_data_2['Ort'] == 'Chicago'),'07:30:00',inplace=True) # Chicago -> 07:30:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_2.groupby(['Startzeit','Ort'],dropna=False, as_index=False)['Jahr'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1>UTC-Zeiten</h1>\n",
    "<p>Da die Wetterdaten in den UTC-Zeiten vorliegen, müssen die Startzeit zu den UTC-Zeiten konvertiert werden.</p>\n",
    "<br>\n",
    "<h2>Regeln der Zeitumstellung</h2>\n",
    "<h3>USA</h3>\n",
    "<a>https://www.nist.gov/pml/time-and-frequency-division/popular-links/daylight-saving-time-dst</a>\n",
    "<p>Begins at 2:00 a.m. on the second Sunday of March (at 2 a.m. the local time time skips ahead to 3 a.m. so there is one less hour in the day)<br>\n",
    "ends at 2:00 a.m. on the first Sunday of November (at 2 a.m. the local time becomes 1 a.m. and that hour is repeated, so there is an extra hour in the day)\n",
    "</p>\n",
    "<h3>Deutschland</h3>\n",
    "<a>http://www.gesetze-im-internet.de/sozv/__2.html</a>\n",
    "<p>(1) Die mitteleuropäische Sommerzeit beginnt jeweils am letzten Sonntag im März um 2 Uhr mitteleuropäischer Zeit. \n",
    "Im Zeitpunkt des Beginns der Sommerzeit wird die Stundenzählung um eine Stunde von 2 Uhr auf 3 Uhr vorgestellt.\n",
    "<br>\n",
    "(2) Die mitteleuropäische Sommerzeit endet jeweils am letzten Sonntag im Oktober um 3 Uhr mitteleuropäischer Sommerzeit. \n",
    "Im Zeitpunkt des Endes der Sommerzeit wird die Stundenzählung um eine Stunde von 3 Uhr auf 2 Uhr zurückgestellt. \n",
    "<br>\n",
    "Die Stunde von 2 Uhr bis 3 Uhr erscheint dabei zweimal. Die erste Stunde (von 2 Uhr bis 3 Uhr mitteleuropäischer Sommerzeit) \n",
    "Wird mit 2A und die zweite Stunde (von 2 Uhr bis 3 Uhr mitteleuropäischer Zeit) mit 2B bezeichnet.\n",
    "</p>\n",
    "<h3>Großbritannien</h3>\n",
    "<a>https://www.gov.uk/when-do-the-clocks-change</a>\n",
    "<p>In the UK the clocks go forward 1 hour at 1am on the last Sunday in March, and back 1 hour at 2am on the last Sunday in October.</p>\n",
    "<hr>\n",
    "\n",
    "<h1>UTC-Zeiten setzen (mit Beachtung der Winter und Sommerzeit)</h1>\n",
    "<h2>Zeiten zu UTC (Winter=normal)</h2>\n",
    "<table>\n",
    "<thead>\n",
    "<tr><td>Stadt</td><td>Winter</td><td>Sommer</td></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>Berlin</td>\n",
    "<td>+1</td>\n",
    "<td>+2</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>London</td>\n",
    "<td>0</td>\n",
    "<td>+1</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>New York</td>\n",
    "<td>-5</td>\n",
    "<td>-4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Chicago</td>\n",
    "<td>-6</td>\n",
    "<td>-5</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Tokyo</td>\n",
    "<td>+9</td>\n",
    "<td>+9</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n",
    "\n",
    "Sommerzeit: Berlin, London und Chicago\n",
    "<br>\n",
    "Winterzeit(normal): NewYork (immer am Tag der Zeitumstellung), Tokyo (hat keine Zeitumstellung)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3 = df_data_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3.groupby(['Startzeit','Ort'],dropna=False, as_index=False)['Jahr'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datum und Uhrzeit zusammenführen\n",
    "df_data_3['Datum_Startzeit_UTC'] = pd.to_datetime(df_data_3['Datum'].astype('str') + 'T' + df_data_3['Startzeit'].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_3.groupby(['Startzeit','Ort'],dropna=False, as_index=False)['Jahr'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Die Uhrzeit unter Berücksichtigung der Winter- und Sommerzeit auf UTC umstellen\n",
    "df_data_3['Datum_Startzeit_UTC'].mask((df_data_3['Ort'] == 'Berlin'),df_data_3['Datum_Startzeit_UTC'] - dt.timedelta(hours=2),inplace=True)\n",
    "df_data_3['Datum_Startzeit_UTC'].mask((df_data_3['Ort'] == 'London'),df_data_3['Datum_Startzeit_UTC'] - dt.timedelta(hours=1),inplace=True)\n",
    "df_data_3['Datum_Startzeit_UTC'].mask((df_data_3['Ort'] == 'Tokyo'),df_data_3['Datum_Startzeit_UTC'] - dt.timedelta(hours=9),inplace=True)\n",
    "df_data_3['Datum_Startzeit_UTC'].mask((df_data_3['Ort'] == 'Chicago'),df_data_3['Datum_Startzeit_UTC'] + dt.timedelta(hours=5),inplace=True)\n",
    "df_data_3['Datum_Startzeit_UTC'].mask((df_data_3['Ort'] == 'NewYork'),df_data_3['Datum_Startzeit_UTC'] + dt.timedelta(hours=5),inplace=True)\n",
    "\n",
    "df_data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auskommentieren um die Uhrzeit zu prüfen\n",
    "#df_data_3[df_data_3['Ort'] == 'Berlin'].groupby('Datum_Startzeit_UTC')['Jahr'].count()\n",
    "#df_data_3[df_data_3['Ort'] == 'London'].groupby('Datum_Startzeit_UTC')['Jahr'].count()\n",
    "#df_data_3[df_data_3['Ort'] == 'Tokyo'].groupby('Datum_Startzeit_UTC')['Jahr'].count()\n",
    "#df_data_3[df_data_3['Ort'] == 'Chicago'].groupby('Datum_Startzeit_UTC')['Jahr'].count()\n",
    "#df_data_3[df_data_3['Ort'] == 'NewYork'].groupby('Datum_Startzeit_UTC')['Jahr'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1>Zeiten in Sekunden umwandeln</h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_4 = df_data_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der angezeigten Zeilen in JNP einstellen\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "#df_data_4.groupby('T_KM_5',dropna=False, as_index=False)['Jahr'].count()\n",
    "\n",
    "# Prüfen auf NaN Felder\n",
    "df_data_4[df_data_4.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeitenfelder mit NaN auf 00:00:00 setzen\n",
    "df_data_4.fillna('00:00:00',inplace=True)\n",
    "df_data_4[df_data_4.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Felder für die Zeiten (in Sekunden) hinzufügen\n",
    "df_data_4['S_KM_5'] = None\n",
    "df_data_4['S_KM_10'] = None\n",
    "df_data_4['S_KM_15'] = None\n",
    "df_data_4['S_KM_20'] = None\n",
    "df_data_4['S_KM_HM'] = None\n",
    "df_data_4['S_KM_25'] = None\n",
    "df_data_4['S_KM_30'] = None\n",
    "df_data_4['S_KM_35'] = None\n",
    "df_data_4['S_KM_40'] = None\n",
    "df_data_4['S_KM_FN'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeiten in Sekunden umwandeln und in die daführ vorgesehenen Felder speichern\n",
    "for index, row in df_data_4.iterrows():    \n",
    "    km5 = time.strptime(row['T_KM_5'],'%H:%M:%S')\n",
    "    km10 = time.strptime(row['T_KM_10'],'%H:%M:%S')\n",
    "    km15 = time.strptime(row['T_KM_15'],'%H:%M:%S')\n",
    "    km20 = time.strptime(row['T_KM_20'],'%H:%M:%S')\n",
    "    kmhm = time.strptime(row['T_KM_HM'],'%H:%M:%S')\n",
    "    km25 = time.strptime(row['T_KM_25'],'%H:%M:%S')\n",
    "    km30 = time.strptime(row['T_KM_30'],'%H:%M:%S')\n",
    "    km35 = time.strptime(row['T_KM_35'],'%H:%M:%S')\n",
    "    km40 = time.strptime(row['T_KM_40'],'%H:%M:%S')\n",
    "    kmfn = time.strptime(row['T_KM_FN'],'%H:%M:%S')\n",
    "\n",
    "    df_data_4.loc[index,['S_KM_5']] = dt.timedelta(hours=km5.tm_hour, minutes=km5.tm_min, seconds=km5.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_10']] = dt.timedelta(hours=km10.tm_hour, minutes=km10.tm_min, seconds=km10.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_15']] = dt.timedelta(hours=km15.tm_hour, minutes=km15.tm_min, seconds=km15.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_20']] = dt.timedelta(hours=km20.tm_hour, minutes=km20.tm_min, seconds=km20.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_HM']] = dt.timedelta(hours=kmhm.tm_hour, minutes=kmhm.tm_min, seconds=kmhm.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_25']] = dt.timedelta(hours=km25.tm_hour, minutes=km25.tm_min, seconds=km25.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_30']] = dt.timedelta(hours=km30.tm_hour, minutes=km30.tm_min, seconds=km30.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_35']] = dt.timedelta(hours=km35.tm_hour, minutes=km35.tm_min, seconds=km35.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_40']] = dt.timedelta(hours=km40.tm_hour, minutes=km40.tm_min, seconds=km40.tm_sec).total_seconds()\n",
    "    df_data_4.loc[index,['S_KM_FN']] = dt.timedelta(hours=kmfn.tm_hour, minutes=kmfn.tm_min, seconds=kmfn.tm_sec).total_seconds()\n",
    "\n",
    "df_data_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reihenfolge der Felder ändern\n",
    "df_data_5 = df_data_4[[\n",
    "    'Jahr','Ort','Geschlecht','Vorname','Nachname','Platz','Datum','Startzeit','Datum_Startzeit_UTC'\n",
    "    ,'T_KM_5','S_KM_5','T_KM_10','S_KM_10','T_KM_15','S_KM_15','T_KM_20','S_KM_20','T_KM_HM','S_KM_HM'\n",
    "    ,'T_KM_25','S_KM_25','T_KM_30','S_KM_30','T_KM_35','S_KM_35','T_KM_40','S_KM_40','T_KM_FN','S_KM_FN'\n",
    "]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platzierung anpassen:\n",
    "# Berlin: Anpassung der Platzierung der Frauen, da beim Berlin-Marathon keine geschlechtspezifische Platzierung gibt. Außer in den Jahren 2018 und 2019\n",
    "# Tokyo: Verschiebung im Jahr 2011, da die Erstplatzierte im Jahre 2012 disqualifiziert wurde. https://de.wikipedia.org/wiki/Tatjana_Alexejewna_Arjassowa\n",
    "# https://worldathletics.org/athletes/russia/tatyana-aryasova-14298087?competitorid=tatyana-aryasova-14298087&competitorid=tatyana-aryasova-14298087&competitorid=tatyana-aryasova-14298087&competitorid=tatyana-aryasova-14298087&counrty=russia&counrty=russia&counrty=russia&counrty=russia&competitorid=tatyana-aryasova-14298087&counrty=russia\n",
    "df_data_5.loc[(df_data_5.Geschlecht == 'W') & (df_data_5.Ort == 'Berlin')].groupby(['Platz','Geschlecht','Ort', 'Jahr'], as_index=True).agg(\n",
    "    {     \n",
    "        'Platz':['count'] #,'max','min']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_data_5['Platz'].loc[(df_data_5.Geschlecht == 'W') & (df_data_5.Ort == 'Berlin') & (df_data_5.Jahr < '2018')].rank(method='first')\n",
    "df_data_5.sort_values(by=['Ort','Jahr','Geschlecht','Platz'],inplace=True)\n",
    "df_data_5.reset_index(drop=True, inplace=True)\n",
    "df_data_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anpassung der Platzierung - Berlin\n",
    "j_prev = None\n",
    "p_new = None\n",
    "for i, row in df_data_5.loc[(df_data_5.Geschlecht == 'W') & (df_data_5.Ort == 'Berlin') & (df_data_5.Jahr < '2018')].iterrows():\n",
    "    j_act = row['Jahr']\n",
    "    if(j_prev == j_act):\n",
    "        p_new = p_new + 1\n",
    "        df_data_5.loc[i,['Platz']] = p_new\n",
    "        #print(p_new)\n",
    "    else:\n",
    "        p_new = 1\n",
    "        df_data_5.loc[i,['Platz']] = p_new\n",
    "        #print(p_new)\n",
    "    j_prev = row['Jahr']\n",
    "\n",
    "df_data_5.loc[(df_data_5.Geschlecht == 'W') & (df_data_5.Ort == 'Berlin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_5.loc[(df_data_5.Geschlecht == 'W') & (df_data_5.Ort == 'Tokyo')].groupby(['Platz','Geschlecht','Ort', 'Jahr'], as_index=True).agg(\n",
    "    {     \n",
    "        'Platz':['count'] #,'max','min']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anpassung der Platzierung - Berlin\n",
    "j_prev = None\n",
    "p_new = None\n",
    "for i, row in df_data_5.loc[(df_data_5.Geschlecht == 'W') & (df_data_5.Ort == 'Tokyo') & (df_data_5.Jahr == '2011')].iterrows():\n",
    "    j_act = row['Jahr']\n",
    "    if(j_prev == j_act):\n",
    "        p_new = p_new + 1\n",
    "        df_data_5.loc[i,['Platz']] = p_new\n",
    "        #print(p_new)\n",
    "    else:\n",
    "        p_new = 1\n",
    "        df_data_5.loc[i,['Platz']] = p_new\n",
    "        #print(p_new)\n",
    "    j_prev = row['Jahr']\n",
    "\n",
    "df_data_5.loc[(df_data_5.Geschlecht == 'W') & (df_data_5.Ort == 'Tokyo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen ob Zeiten nicht erfasst wurden bzw. auf 0.0 stehen\n",
    "df_data_5.loc[df_data_5.isin([0.0]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_6 = df_data_5.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalte hinzufügen die Datensätze mit ungültigen Zwischenzeiten markiert.\n",
    "df_data_6['ZZ_INVALID'] = 'F'\n",
    "\n",
    "# Die enstprechenden Datensätze mit ZZ_INVALID ungültig markieren\n",
    "df_data_6['ZZ_INVALID'].mask((df_data_6.isin([0.0]).any(axis=1)),'T',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_6.loc[df_data_6.isin([0.0]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_6.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_6.groupby(['Geschlecht'], as_index=True).agg(\n",
    "    {     \n",
    "        'S_KM_FN':['max','min','mean','median']\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle Datensätze in eine CSV-Datei speichern.\n",
    "file_name_prepared = data_path + \"daten_wmm_all_prepared.csv\"\n",
    "df_data_6.to_csv(file_name_prepared, sep=';', index=False, encoding='utf8')\n",
    "\n",
    "# Dataframe serialisieren (Pickle) für die spätere Verwendungen mit den Wetterdaten\n",
    "file_name_prepared_p = data_path + \"daten_wmm_all_prepared.p\"\n",
    "pickle.dump(df_data_6, open(file_name_prepared_p, \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a170f962d07ed8515a1e0cfe90051c8c49c07a10f515ca6de22ae850428164e9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
